# Data Engineering Portfolio

ğŸš€ **Job-ready data engineering portfolio** showcasing real-world pipelines, ETL/ELT workflows, streaming systems, data quality frameworks, and lakehouse architectures.

This repository demonstrates hands-on experience with **Python, SQL, Airflow, dbt, Spark, Kafka, Delta Lake, Docker, Terraform, and cloud-ready data architecture patterns**.

---

## ğŸ“‚ Portfolio Projects

All production-ready projects are located in:

ğŸ‘‰ **`/data-engineering-job-ready-projects`**

Each project includes:
- Real datasets (no placeholders)
- Fully runnable code
- Clear architecture
- Dockerized environments
- Testing / validation
- Professional documentation

---

## ğŸ§© Projects Overview

### **1ï¸âƒ£ Batch ETL Pipeline â€” Airflow + dbt + PostgreSQL**
ğŸ“ `01_batch_etl_dbt_airflow`

**What it shows**
- End-to-end batch ETL pipeline
- Raw â†’ Staging â†’ Mart data modeling
- Orchestration with Apache Airflow
- Analytics engineering with dbt
- Data quality tests (not null, unique, accepted values)

**Tech Stack**
- Python, SQL
- Apache Airflow
- dbt
- PostgreSQL
- Docker

---

### **2ï¸âƒ£ Real-Time Streaming Pipeline â€” Kafka + Spark + Delta Lake**
ğŸ“ `02_streaming_kafka_spark_delta`

**What it shows**
- Real-time clickstream ingestion
- Kafka event streaming
- Spark Structured Streaming aggregation
- Delta Lake storage (lakehouse pattern)
- Analytical querying with DuckDB

**Tech Stack**
- Kafka
- Spark Structured Streaming
- Delta Lake
- Python
- Docker

---

### **3ï¸âƒ£ Data Quality & Observability â€” Great Expectations**
ğŸ“ `03_data_quality_observability`

**What it shows**
- Automated data quality checks
- Schema validation
- Range, null, uniqueness enforcement
- Pipeline failure on quality violations
- JSON validation reports

**Tech Stack**
- Python
- Great Expectations
- Pandas
- CI-ready structure

---

### **4ï¸âƒ£ Lakehouse Architecture + IaC â€” DuckDB + Parquet + Terraform**
ğŸ“ `04_lakehouse_iac_aws_style_local`

**What it shows**
- Bronze / Silver / Gold lakehouse architecture
- Parquet-based analytics
- DuckDB for fast local querying
- AWS-style infrastructure using Terraform
- Glue / Athena / S3 conceptual mapping

**Tech Stack**
- DuckDB
- Parquet
- Python
- Terraform (AWS-style IaC)

---

## ğŸ§  Skills Demonstrated

- Data pipeline design (batch & streaming)
- Analytics engineering (dbt)
- Orchestration (Airflow)
- Data quality & observability
- Lakehouse architectures
- Cloud-ready infrastructure design
- SQL & Python for data engineering
- Dockerized, reproducible systems

---

## ğŸ“¸ What Recruiters Can Verify

Each project provides clear evidence:
- Successful Airflow DAG runs
- Passing dbt tests
- Streaming jobs processing live data
- Generated parquet / delta tables
- Data quality validation reports

---

## ğŸ›  How to Use This Repo

1. Clone the repo
2. Navigate into `data-engineering-job-ready-projects`
3. Open any project folder
4. Follow the project-specific README

Each project runs **locally** with minimal setup.

---

## ğŸ“œ License
MIT License â€” free to use, fork, and reference.
